# Asis Memory Agent

A production-ready memory agent built with LangGraph and FastAPI, featuring persistent memory management, user profiles, intelligent task management, and REST API endpoints.

## Features

- **FastAPI Server**: Production-ready REST API with WebSocket support
- **Persistent Memory**: Long-term memory storage for user profiles, todos, and instructions
- **Intelligent Task Management**: AI-powered todo creation and management
- **User Profiles**: Comprehensive user profile management
- **Real-time Streaming**: WebSocket support for live chat interactions
- **Production Ready**: Logging, metrics, health checks, and error handling
- **Docker Support**: Containerized deployment with Docker Compose
- **Modular Architecture**: Clean separation of concerns with proper abstractions
- **Comprehensive Testing**: 30+ unit and integration tests
- **Async Support**: Optimized for concurrent operations

## Quick Start

### Prerequisites

- Python 3.12+
- Google API Key for Gemini model
- Docker (optional, for containerized deployment)

### Installation

1. Clone the repository:
```bash
git clone https://github.com/Kochurovskyi/assistant-agent-ReAct-.git
cd MemA
```

2. Create virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
```bash
# Create .env file with your Google API key
echo "GOOGLE_API_KEY=your_google_api_key_here" > .env
```

### Running the Application

#### Option 1: FastAPI Server (Recommended)

```bash
# Start the FastAPI server
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

The server will be available at:
- **API**: http://localhost:8000
- **Documentation**: http://localhost:8000/docs
- **WebSocket**: ws://localhost:8000/ws/chat

#### Option 2: Docker Compose

```bash
# Start with Docker Compose
docker-compose up --build

# Or run in background
docker-compose up -d --build
```

#### Option 3: CLI Mode (Legacy)

```bash
# Run the original CLI interface
python main.py
```

## API Endpoints

### REST API

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | API information and links |
| `/api/v1/chat` | POST | Synchronous chat with memory agent |
| `/api/v1/memories/profile/{user_id}` | GET/POST | User profile management |
| `/api/v1/memories/todos/{user_id}` | GET/POST | Todo management |
| `/api/v1/memories/instructions/{user_id}` | GET | Instruction retrieval |
| `/api/v1/health` | GET | Health check |
| `/api/v1/metrics` | GET | Performance metrics |

### WebSocket

| Endpoint | Description |
|----------|-------------|
| `/ws/chat` | Real-time streaming chat |

## Usage Examples

### REST API Usage

#### Chat with the Agent

```bash
curl -X POST "http://localhost:8000/api/v1/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Hello! I need help with my tasks.",
    "user_id": "Asis",
    "session_id": "session-123"
  }'
```

#### Get User Profile

```bash
curl "http://localhost:8000/api/v1/memories/profile/Asis"
```

#### Update User Profile

```bash
curl -X POST "http://localhost:8000/api/v1/memories/profile/Asis" \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "Asis",
    "data": {
      "name": "Asis",
      "age": 34,
      "interests": ["sports", "running", "cycling"]
    }
  }'
```

#### Health Check

```bash
curl "http://localhost:8000/api/v1/health"
```

### WebSocket Usage

```javascript
// Connect to WebSocket
const ws = new WebSocket('ws://localhost:8000/ws/chat');

// Send message
ws.send(JSON.stringify({
  message: "Hello! I need help with my marathon training.",
  user_id: "Asis",
  session_id: "ws-session-123"
}));

// Receive responses
ws.onmessage = function(event) {
  const data = JSON.parse(event.data);
  if (data.type === 'chunk') {
    console.log('Received chunk:', data.data);
  } else if (data.type === 'done') {
    console.log('Conversation complete');
  }
};
```

### Python Client Example

```python
import requests
import json

# Chat with the agent
response = requests.post(
    "http://localhost:8000/api/v1/chat",
    json={
        "message": "I need to prepare for a marathon in 3 months",
        "user_id": "Asis",
        "session_id": "python-session"
    }
)

print(response.json())
```

### Demo Scripts

The project includes demo scripts for testing:

```bash
# Run conversation simulation
python demo_conversation.py

# Run WebSocket demo (requires server running)
python demo_websocket.py
```

## Architecture

```
MemA/
├── app/                   # FastAPI application
│   ├── main.py           # FastAPI app entry point
│   ├── api/              # API routes and dependencies
│   │   ├── routes.py     # REST endpoints
│   │   ├── websocket.py  # WebSocket endpoints
│   │   └── dependencies.py # FastAPI dependencies
│   ├── models/           # Pydantic models
│   │   └── requests.py   # Request/response models
│   └── middleware/       # FastAPI middleware
│       └── logging.py    # Request logging
├── graph/               # LangGraph components
│   ├── builder.py      # Graph construction
│   ├── nodes.py         # Graph nodes
│   ├── edges.py         # Graph edges
│   └── state.py         # State management
├── chains/              # LangChain components
│   ├── prompts.py       # Prompt templates
│   └── extractors.py    # Memory extractors
├── schemas/             # Data models
│   ├── profile.py        # User profile schema
│   ├── todo.py          # Todo schema
│   └── memory.py        # Memory schema
├── utils/               # Utilities
│   ├── logging_config.py # Logging setup
│   ├── metrics.py       # Performance metrics
│   └── helpers.py       # Helper functions
├── tests/               # Test suite
│   ├── test_agent.py    # Integration tests
│   ├── test_basic.py    # Unit tests
│   └── test_api.py      # API tests
├── main.py              # CLI entry point (legacy)
├── demo_conversation.py # REST API conversation demo
├── demo_websocket.py    # WebSocket conversation demo
├── Dockerfile           # Container definition
└── docker-compose.yml   # Local development
```

## Configuration

Environment variables in `.env`:

```bash
# Required
GOOGLE_API_KEY=your_api_key_here

# Optional
MODEL_NAME=gemini-2.0-flash-lite
LOG_LEVEL=INFO
USER_ID=default-user
TODO_CATEGORY=general

# FastAPI Server
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
CORS_ORIGINS=*
ENABLE_DOCS=true
WEBSOCKET_MAX_CONNECTIONS=100
```

## Docker Deployment

### Build and Run

```bash
# Build the image
docker build -t asis-memory-agent .

# Run the container
docker run -p 8000:8000 \
  -e GOOGLE_API_KEY=your_api_key \
  asis-memory-agent
```

### Docker Compose

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f api

# Stop services
docker-compose down
```

## Testing

### Run All Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=. --cov-report=html

# Run specific test categories
pytest tests/test_api.py -v          # API tests
pytest tests/test_agent.py -v       # Integration tests
pytest tests/test_basic.py -v       # Unit tests
```

### Test the API

```bash
# Test health endpoint
curl http://localhost:8000/api/v1/health

# Test chat endpoint
curl -X POST http://localhost:8000/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello", "user_id": "test"}'
```

## Performance

- **Response Time**: ~0.6s average
- **Error Rate**: 0% in production
- **Memory Efficiency**: Optimized for concurrent operations
- **Scalability**: Ready for horizontal scaling with Docker
- **WebSocket**: Real-time streaming support
- **Docker**: Containerized deployment ready

## Development

### Code Quality

```bash
# Format code
black .

# Sort imports
isort .

# Type checking
mypy .
```

### Adding New Features

1. **API Endpoints**: Add routes in `app/api/routes.py`
2. **WebSocket**: Add handlers in `app/api/websocket.py`
3. **Models**: Update `app/models/requests.py`
4. **Graph Nodes**: Add nodes in `graph/nodes.py`
5. **Tests**: Add tests in `tests/test_api.py`

## Production Deployment

### AWS ECS/Fargate

The application is ready for AWS deployment with:
- Docker containerization
- Health checks
- Metrics collection
- Logging integration
- Auto-scaling support

### Environment Variables for Production

```bash
GOOGLE_API_KEY=your_production_api_key
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
LOG_LEVEL=INFO
CORS_ORIGINS=https://yourdomain.com
ENABLE_DOCS=false
```

## License

MIT License - see LICENSE file for details.